{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import altair as alt\n",
    "import sys\n",
    "sys.path.append('figure_scripts/')\n",
    "\n",
    "import plot_scripts as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_table = pd.read_csv('supp_fig_10_input.tsv', sep='\\t')\n",
    "success_table['UDN_ID'] =[x.split('_')[0] for x in success_table['ID']]\n",
    "print(len(set(success_table['ID'])),'genes')\n",
    "print(len(success_table), 'variants')\n",
    "print(len(set(success_table['UDN_ID'])), 'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv('GS_ID_mapping.csv')\n",
    "mapped= []\n",
    "for i, row in success_table.iterrows():\n",
    "    ID = row['ID']\n",
    "    mapped_id = mapping[mapping['ID']==ID]['Dumb_ID'].item()\n",
    "    mapped.append(mapped_id)\n",
    "success_table['Dumb_ID'] = mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = [\n",
    "                'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noinheritance_noWL',\n",
    "                'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_singleton_noWL',\n",
    "                'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noterms_noWL',\n",
    "                'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_random_fromHPO_noWL',\n",
    "                'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL',\n",
    "                'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_singleton_noinheritance_noWL',\n",
    "                'curated_noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL', \n",
    "                'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_random_fromUDN_add5noWL', \n",
    "                'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_random_fromUDN_add10noWL',\n",
    "                'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_random_fromUDN_add20noWL']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A: Affect of randomly sampled phenotypes or no phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtypes  = ['noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL', 'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_random_fromHPO_noWL','noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noterms_noWL',\n",
    " 'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_random_fromUDN_add5noWL', 'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_random_fromUDN_add10noWL','noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_random_fromUDN_add20noWL']\n",
    "\n",
    "df,denom = ps.create_df(300, runtypes, success_table)\n",
    "plot_A = ps.create_plot(denom, df, domain, 'category20', False, domain).properties(height=350, width=400)\n",
    "\n",
    "plot_A.configure_axis(\n",
    "    labelFontSize=15,\n",
    "    labelPadding= 5,\n",
    "    tickSize=8,\n",
    "    titleFontSize=15,\n",
    "    labelFont='arial',\n",
    "    titleFont='arial',\n",
    "    labelLimit=0\n",
    "    ).configure_legend(\n",
    "        labelLimit=0,labelFontSize=13, titleFontSize=15, labelFont='arial', titleFont='arial')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_data = pd.read_csv('udn_phenotype_data.csv') ##from \"prune_term_lists.py\"\n",
    "changed = list(phenotype_data[phenotype_data['Curated_Changed']=='Changed']['ID'])\n",
    "print(len(changed))\n",
    "changed.remove('UDN195171')\n",
    "print(len(changed))\n",
    "\n",
    "success_table['UDN_ID'] =[x.split('_')[0] for x in success_table['ID']]\n",
    "trimmed_success_table =  success_table[success_table['UDN_ID'].isin(changed)]\n",
    "print(len(set(trimmed_success_table['ID'])),'genes')\n",
    "print(len(trimmed_success_table), 'variants')\n",
    "print(len(set(trimmed_success_table['UDN_ID'])), 'patients')\n",
    "ids = list(set(trimmed_success_table['UDN_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "domain = ['Comprehensive', 'Curated', 'Variant']\n",
    "_range = ['#28993C','lightgrey','#e38cbb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "removed = []\n",
    "added = []\n",
    "for id in set(ids):\n",
    "    old_terms = set(phenotype_data[phenotype_data['ID']==id]['Terms'].item().split('; '))\n",
    "    curated_terms = set(phenotype_data[phenotype_data['ID']==id]['Curated_Terms'].item().split('; '))\n",
    "    \n",
    "    difference = len(old_terms) - len(curated_terms)\n",
    "    \n",
    "    removed_terms = set(old_terms) - set(curated_terms)\n",
    "\n",
    "    added_terms = set(curated_terms) - set(old_terms)\n",
    "    added += list(added_terms)\n",
    "    removed += list(removed_terms)\n",
    "    data.append([id, len(old_terms), 'Comprehensive', difference, len(removed_terms), len(added_terms)])\n",
    "    data.append([id, len(curated_terms), 'Curated', difference,len(removed_terms), len(added_terms)])\n",
    "df_summary = pd.DataFrame(data, columns= ['ID', 'Num_Terms', 'Class', 'Diff', 'Removed', 'Added'])\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhpo import Ontology, HPOSet\n",
    "_=Ontology()\n",
    "print(HPOSet.from_queries(removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = []\n",
    "for term in set(removed):\n",
    "    try:\n",
    "       # data2.append([term, removed.count(term), Ontology.get_hpo_object(term).name])\n",
    "        data2.append([term, removed.count(term), round(((removed.count(term)/len(ids))*100),1), Ontology.get_hpo_object(term).name])\n",
    "    except:\n",
    "       # data2.append([term, removed.count(term), 'Unknown_Term'])\n",
    "        data2.append([term, removed.count(term),round((removed.count(term)/len(ids))*100,2), 'Unknown_Term'])\n",
    "\n",
    "df2 = pd.DataFrame(data2, columns=['Term', 'numPatients' ,'Percent_Patients','TermName'])\n",
    "\n",
    "print(len(removed), 'HPO terms used')\n",
    "print(len(set(removed)), 'unique HPO terms used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = df2.sort_values(by='Percent_Patients').sort_values(by='Percent_Patients', ascending=False).reset_index(drop=True)#.head(24)\n",
    "\n",
    "base = alt.Chart(source, title=str(len(ids)) + ' UDN Individuals ~ Removed HPO Terms')\n",
    "\n",
    "bars=base.mark_bar().encode(\n",
    "    y=alt.Y('TermName:N', sort='-x', title=None).axis(offset=5, domainOpacity=0),\n",
    "    x=alt.X('numPatients', title='Number of Benchmarking Patients with HPO Term Removed'), \n",
    "    tooltip = ['numPatients','PhenoCat_IC:N'],\n",
    ")\n",
    "\n",
    "text = base.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=3,\n",
    "    color='black',\n",
    "    size=14\n",
    ").encode(\n",
    "    y=alt.Y('TermName:N', sort='-x', title=None).axis(offset=5, domainOpacity=0),\n",
    "    x=alt.X('numPatients'), \n",
    "    text='numPatients:Q'\n",
    ")\n",
    "removed_terms_plot = alt.layer(bars).resolve_scale(color='independent').properties(height=350, width=250)\n",
    "\n",
    "removed_terms_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(df_summary)\n",
    "box = base.mark_boxplot().encode(\n",
    "    alt.Y(\"Num_Terms:Q\", title='Number of HPO terms assigned to proband').scale(zero=False),\n",
    "    alt.X('Class:N', title=None),\n",
    "    color=alt.Color('Class:N', scale=alt.Scale(domain=domain, range=_range))\n",
    ")\n",
    "\n",
    "rule = base.mark_rule(color='black', strokeWidth=2, strokeDash=[2,2]).encode(\n",
    "    x='median(Num_Terms):Q',\n",
    "    tooltip=['median(Num_Terms):Q']\n",
    ")\n",
    "\n",
    "text = base.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=-5,\n",
    "    dy=-12,\n",
    "    color='black',\n",
    "    size=10\n",
    ").encode(\n",
    "    x='Class:N',\n",
    "    y=alt.Y('median(Num_Terms):Q'), \n",
    "    #color='Class:N',\n",
    "    text='median(Num_Terms):Q'\n",
    ")\n",
    "term_boxplot = alt.layer(box, text).properties(height=300, width=100)#.configure_axis(grid=False,\n",
    "    # labelPadding= 5,\n",
    "    # labelLimit=0,\n",
    "    # labelFontSize=12, \n",
    "    # titleFontSize=15, labelFont='arial', tickSize=8).configure_legend(\n",
    "    #     labelLimit=0,labelFontSize=15, titleFontSize=15, labelFont='arial')\n",
    "\n",
    "term_boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "to_plot = []\n",
    "to_plot_large = []\n",
    "to_plot_worse = []\n",
    "\n",
    "unfiltered_run_type = 'noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL'\n",
    "filtered_run_type = 'curated_noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL'\n",
    "successes = trimmed_success_table[trimmed_success_table['Variant_Level_noMOI_noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL'] == 'Variant_Present_noMOI']\n",
    "\n",
    "for i, patient_row in successes.iterrows():\n",
    "    ID = patient_row['Dumb_ID']\n",
    "    unfiltered_rank = patient_row['Variant_Level_noMOI_rank_' + unfiltered_run_type]\n",
    "    filtered_rank = patient_row['Variant_Level_noMOI_rank_' + filtered_run_type]\n",
    "    if filtered_rank == 'N/A':\n",
    "        filtered_rank = 0\n",
    "        print(ID, unfiltered_rank)\n",
    "    difference = unfiltered_rank - filtered_rank\n",
    "    data.append([ID, unfiltered_rank, difference, 'Comprehensive'])\n",
    "    data.append([ID, filtered_rank, difference, 'Curated'])\n",
    "\n",
    "    if unfiltered_rank != filtered_rank:\n",
    "        if unfiltered_rank > filtered_rank:\n",
    "            if unfiltered_rank > 20:\n",
    "                to_plot_large.append(ID)\n",
    "            else:\n",
    "                 to_plot.append(ID)\n",
    "        else:\n",
    "            to_plot_worse.append(ID)\n",
    "\n",
    "df = pd.DataFrame(data, columns=['ID', 'Rank', 'Diff', 'RunType'])\n",
    "print(len(to_plot))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "source = df[df['ID'].isin(to_plot)].sort_values(by='Rank', ascending=False)\n",
    "order = list(source['ID']) + ['UDN197_DENND5B']\n",
    "print(len(source)/2)\n",
    "rank_change1 = alt.Chart(source).mark_circle(size=100, filled=True, stroke='black',strokeWidth=1,opacity=1).encode(\n",
    "    x=alt.X('ID', axis=alt.Axis(labelAngle=-60)).scale(domain=order),\n",
    "    y=alt.Y('Rank', title='Exomiser Rank of Causative Variant'),#, scale=alt.Scale(domain=[0,29.1])),\n",
    "    color=alt.Color('RunType', sort=['Unfiltered', 'Filtered'], scale=alt.Scale(domain = domain, range=_range), legend=alt.Legend(\n",
    "        orient='top',\n",
    "        direction='horizontal',\n",
    "        titleAnchor='middle')),\n",
    "    tooltip = ['RunType', 'ID', 'Rank', 'Diff']\n",
    ").properties(\n",
    "    height=200,\n",
    "    width=400)\n",
    "source = df[df['ID'].isin(to_plot_large)].sort_values(by='Rank', ascending=False)\n",
    "print(order)\n",
    "order = list(source['ID'])\n",
    "print(len(source)/2)\n",
    "rank_change2 = alt.Chart(source).mark_circle(size=100, filled=True, stroke='black', strokeWidth=1, opacity=1).encode(\n",
    "    x=alt.X('ID',  axis=None).scale(domain=order),\n",
    "    y=alt.Y('Rank', title=None, scale=alt.Scale(domain=[70,73])),\n",
    "    #size = 'Term_Diff',\n",
    "    color=alt.Color('RunType', sort=['Curated', 'Comprehensive'], scale=alt.Scale(domain = domain, range=_range), legend=alt.Legend(\n",
    "        orient='top',\n",
    "        direction='horizontal',\n",
    "        titleAnchor='middle')),\n",
    "    tooltip = ['RunType', 'ID', 'Rank', 'Diff']\n",
    ").properties(\n",
    "    height=40, width=400)\n",
    "\n",
    "rank_improvements = alt.vconcat(rank_change2, rank_change1, spacing=5).resolve_scale(x=\"shared\")\n",
    "rank_improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = df[df['ID'].isin(to_plot_worse)].sort_values(by='Rank', ascending=False)\n",
    "order = list(source['ID'])\n",
    "print(len(source)/2)\n",
    "rank_worsen1 = alt.Chart(source[source['ID']!= 'UDN57_SPEN']).mark_circle(size=100, filled=True, stroke='black',strokeWidth=1, opacity=1).encode(\n",
    "    x=alt.X('ID',  axis=alt.Axis(labelAngle=-60)).scale(domain=['UDN26_PIGN','UDN105_SNUPN', 'UDN57_SPEN']),\n",
    "    y=alt.Y('Rank', title='Exomiser Rank of Causative Variant'),#, scale=alt.Scale(domain=[0,29.1])),\n",
    "    #size = 'Term_Diff',\n",
    "    color=alt.Color('RunType', sort=['Curated', 'Comprehensive'], scale=alt.Scale(domain = domain, range=_range), legend=alt.Legend(\n",
    "        orient='top',\n",
    "        direction='horizontal',\n",
    "        titleAnchor='middle')),\n",
    "    tooltip = ['RunType', 'ID', 'Rank', 'Diff']\n",
    ").properties(\n",
    "    height=200,\n",
    "    width=100\n",
    ")\n",
    "rank_worsen2 = alt.Chart(source[source['ID']== 'UDN57_SPEN']).mark_circle(size=100, filled=True, stroke='black', strokeWidth=1, opacity=1).encode(\n",
    "    x=alt.X('ID', axis=None).scale(domain=['UDN26_PIGN','UDN105_SNUPN', 'UDN57_SPEN']),\n",
    "    y=alt.Y('Rank', title=None, scale=alt.Scale(domain=[65,69])),\n",
    "    #size = 'Term_Diff',\n",
    "    color=alt.Color('RunType', sort=['Curated', 'Comprehensive'], scale=alt.Scale(domain = domain, range=_range), legend=alt.Legend(\n",
    "        orient='top',\n",
    "        direction='horizontal',\n",
    "        titleAnchor='middle')),\n",
    "    tooltip = ['RunType', 'ID', 'Rank', 'Diff']\n",
    ").properties(\n",
    "    height=40, width=100)\n",
    "\n",
    "rank_worsen = alt.vconcat(rank_worsen2,rank_worsen1, spacing=5).resolve_scale(x=\"shared\")\n",
    "rank_worsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "trimmed_success_table=trimmed_success_table[trimmed_success_table['Dumb_ID'].isin(to_plot+to_plot_large + to_plot_worse)]\n",
    "for i, patient_row in trimmed_success_table.iterrows():\n",
    "    ID = patient_row['Dumb_ID']\n",
    "\n",
    "    trimmed_score =list(trimmed_success_table[trimmed_success_table['Dumb_ID']==ID]['Variant_Level_noMOI_pheno_curated_noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL'])[0]\n",
    "    gateway_score= list(trimmed_success_table[trimmed_success_table['Dumb_ID']==ID]['Variant_Level_noMOI_pheno_noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL'])[0]\n",
    "    variant_score =list(trimmed_success_table[trimmed_success_table['Dumb_ID']==ID]['Variant_Level_noMOI_variant_curated_noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL'])[0]\n",
    "    trimmed_rank =list(trimmed_success_table[trimmed_success_table['Dumb_ID']==ID]['Variant_Level_noMOI_rank_curated_noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL'])[0]\n",
    "    gateway_rank= list(trimmed_success_table[trimmed_success_table['Dumb_ID']==ID]['Variant_Level_noMOI_rank_noN_filtered_15_85_human_revel_mvp_alphaM_spliceAI_noWL'])[0]\n",
    "\n",
    "    old_terms = df_summary[(df_summary['ID'] == patient_row['ID'].split('_')[0]) & (df_summary['Class']=='Comprehensive')]['Num_Terms'].item()\n",
    "    new_terms = df_summary[(df_summary['ID'] == patient_row['ID'].split('_')[0]) & (df_summary['Class']=='Curated')]['Num_Terms'].item()\n",
    "\n",
    "    diff = trimmed_score - gateway_score\n",
    "    scores.append([ID, trimmed_score,'Curated', diff,trimmed_rank, new_terms])\n",
    "    scores.append([ID, gateway_score,'Comprehensive', diff,gateway_rank, old_terms])\n",
    "    scores.append([ID, variant_score,'Variant', diff, trimmed_rank,''])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns = ['ID', 'Score', 'Class', 'Diff', 'Rank', 'Terms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(scores_df)\n",
    "# order = list(scores_df[scores_df['Class']=='Variant'].sort_values(by='Score')['ID'])\n",
    "box = base.mark_circle(size=80, filled=True, stroke='black', strokeWidth=1, opacity=1).encode(\n",
    "    alt.Y(\"Score:Q\", title='Gene Phenotype or Variant Score').scale(zero=False),\n",
    "    x=alt.X('ID', title='',sort=order, axis=alt.Axis(labelAngle=-60)),\n",
    "    color=alt.Color('Class:N', scale=alt.Scale(domain=domain, range=_range)),\n",
    "    tooltip=['Class', 'Rank', 'Score']\n",
    ")\n",
    "\n",
    "text = base.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    color='black',\n",
    "    size=10\n",
    ").encode(\n",
    "    x='ID:N',\n",
    "    y=alt.Y('Score:Q'), \n",
    "    #color='Class:N',\n",
    "    text='Rank:Q'\n",
    ")\n",
    "phenotype_score_boxplot = alt.layer(box).properties(height=250, width=350)#.configure_axis(grid=False,\n",
    "    # labelPadding= 5,\n",
    "    # labelLimit=0,\n",
    "    # labelFontSize=12, \n",
    "    # titleFontSize=15, labelFont='arial', tickSize=8).configure_legend(\n",
    "    #     labelLimit=0,labelFontSize=15, titleFontSize=15, labelFont='arial')\n",
    "phenotype_score_boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df = scores_df[scores_df['Class']!='Variant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(g_df)\n",
    "# order = list(scores_df[scores_df['Class']=='Variant'].sort_values(by='Score')['ID'])\n",
    "box = base.mark_circle(size=80, filled=True, stroke='black', strokeWidth=1, opacity=1).encode(\n",
    "    alt.Y(\"Terms:Q\", title='Number of HPO Terms').scale(zero=False),\n",
    "    x=alt.X('ID', title='',sort=order, axis=alt.Axis(labelAngle=-60)),\n",
    "    color=alt.Color('Class:N', scale=alt.Scale(domain=domain, range=_range)),\n",
    "    tooltip=['Class', 'Rank', 'Score']\n",
    ")\n",
    "\n",
    "text = base.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=8,\n",
    "    color='black',\n",
    "    size=10\n",
    ").encode(\n",
    "    x=alt.X('ID', title='',sort=order, axis=alt.Axis(labelAngle=-60)),\n",
    "    y=alt.Y('Terms:Q'), \n",
    "    #color='Class:N',\n",
    "    text='Terms:Q'\n",
    ")\n",
    "phenotype_term_counts = alt.layer(box,text).properties(height=300, width=500)#.configure_axis(grid=False,\n",
    "    # labelPadding= 5,\n",
    "    # labelLimit=0,\n",
    "    # labelFontSize=12, \n",
    "    # titleFontSize=15, labelFont='arial', tickSize=8).configure_legend(\n",
    "    #     labelLimit=0,labelFontSize=15, titleFontSize=15, labelFont='arial')\n",
    "phenotype_term_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
